{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e927453b",
   "metadata": {},
   "source": [
    "## Подключение всех необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d506950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import csv\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "878e809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "356576bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gtts\n",
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae32041f",
   "metadata": {},
   "source": [
    "# Обработка аудио файлов и создание csv файла (датасета) с признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "938e4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 'filename chroma_stft rms spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}'\n",
    "header += ' label'\n",
    "header = header.split()\n",
    "\n",
    "file = open('dataset.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "\n",
    "\n",
    "genres = [\"angry\", \"sad\", \"happy\", \"fear\", \"disgust\", \"neutral\", \"pleasant_surprised\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b624dcc",
   "metadata": {},
   "source": [
    "## 1. Заполнение csv файла данными из датасета TESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3175f6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#создание датасета (уже создан)\n",
    "\n",
    "for genr in genres:\n",
    "    for filename in os.listdir(f\"./TESS/{genr}\"):\n",
    "        if filename == \".DS_Store\":\n",
    "            continue\n",
    "        songname = f\"./TESS/{genr}/{filename}\"\n",
    "        y, sr = librosa.load(songname, mono=True)\n",
    "\n",
    "        rms = librosa.feature.rms(y=y)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "\n",
    "        feature_row = f'{filename} {np.mean(chroma_stft)} {np.mean(rms)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "\n",
    "        for e in mfcc:\n",
    "            feature_row += f' {np.mean(e)}'\n",
    "        feature_row += f' {genr}'\n",
    "        file = open('dataset.csv', 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(feature_row.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd74b0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rms</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OAF_king_angry.wav</td>\n",
       "      <td>0.275622</td>\n",
       "      <td>0.030611</td>\n",
       "      <td>2188.212323</td>\n",
       "      <td>2216.685828</td>\n",
       "      <td>3984.838867</td>\n",
       "      <td>0.101251</td>\n",
       "      <td>-409.611389</td>\n",
       "      <td>49.869926</td>\n",
       "      <td>-4.398498</td>\n",
       "      <td>...</td>\n",
       "      <td>2.592276</td>\n",
       "      <td>-1.143469</td>\n",
       "      <td>6.888781</td>\n",
       "      <td>-2.693643</td>\n",
       "      <td>-0.001758</td>\n",
       "      <td>3.174780</td>\n",
       "      <td>-2.620514</td>\n",
       "      <td>-2.477835</td>\n",
       "      <td>-10.139343</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OAF_rot_angry.wav</td>\n",
       "      <td>0.255442</td>\n",
       "      <td>0.029819</td>\n",
       "      <td>2210.799896</td>\n",
       "      <td>2256.036375</td>\n",
       "      <td>3958.520508</td>\n",
       "      <td>0.094523</td>\n",
       "      <td>-388.562958</td>\n",
       "      <td>62.383816</td>\n",
       "      <td>-10.005765</td>\n",
       "      <td>...</td>\n",
       "      <td>7.899292</td>\n",
       "      <td>-2.929130</td>\n",
       "      <td>-0.960948</td>\n",
       "      <td>5.303476</td>\n",
       "      <td>2.484355</td>\n",
       "      <td>-8.288725</td>\n",
       "      <td>-10.059808</td>\n",
       "      <td>-6.154644</td>\n",
       "      <td>-11.985009</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OAF_hire_angry.wav</td>\n",
       "      <td>0.260370</td>\n",
       "      <td>0.027054</td>\n",
       "      <td>2125.701685</td>\n",
       "      <td>2094.000747</td>\n",
       "      <td>3457.238582</td>\n",
       "      <td>0.099099</td>\n",
       "      <td>-405.522919</td>\n",
       "      <td>63.094051</td>\n",
       "      <td>-23.975689</td>\n",
       "      <td>...</td>\n",
       "      <td>15.111687</td>\n",
       "      <td>-0.581255</td>\n",
       "      <td>4.787343</td>\n",
       "      <td>0.885953</td>\n",
       "      <td>3.654622</td>\n",
       "      <td>-7.576045</td>\n",
       "      <td>-7.957401</td>\n",
       "      <td>-2.184226</td>\n",
       "      <td>-12.305842</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YAF_numb_angry.wav</td>\n",
       "      <td>0.294158</td>\n",
       "      <td>0.065479</td>\n",
       "      <td>3015.999826</td>\n",
       "      <td>2162.348090</td>\n",
       "      <td>5117.997675</td>\n",
       "      <td>0.175675</td>\n",
       "      <td>-306.055756</td>\n",
       "      <td>40.761471</td>\n",
       "      <td>-11.389371</td>\n",
       "      <td>...</td>\n",
       "      <td>12.775775</td>\n",
       "      <td>-8.295956</td>\n",
       "      <td>7.579611</td>\n",
       "      <td>2.391619</td>\n",
       "      <td>-3.962322</td>\n",
       "      <td>0.059314</td>\n",
       "      <td>1.836014</td>\n",
       "      <td>-8.889676</td>\n",
       "      <td>1.407364</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YAF_seize_angry.wav</td>\n",
       "      <td>0.294656</td>\n",
       "      <td>0.034536</td>\n",
       "      <td>4283.769099</td>\n",
       "      <td>2234.925543</td>\n",
       "      <td>6427.347542</td>\n",
       "      <td>0.288214</td>\n",
       "      <td>-372.893768</td>\n",
       "      <td>4.074799</td>\n",
       "      <td>14.011549</td>\n",
       "      <td>...</td>\n",
       "      <td>8.256427</td>\n",
       "      <td>-11.015532</td>\n",
       "      <td>5.854211</td>\n",
       "      <td>-2.778954</td>\n",
       "      <td>-2.978256</td>\n",
       "      <td>4.731396</td>\n",
       "      <td>-0.114971</td>\n",
       "      <td>-6.256421</td>\n",
       "      <td>6.497686</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename  chroma_stft       rms  spectral_centroid  \\\n",
       "0   OAF_king_angry.wav     0.275622  0.030611        2188.212323   \n",
       "1    OAF_rot_angry.wav     0.255442  0.029819        2210.799896   \n",
       "2   OAF_hire_angry.wav     0.260370  0.027054        2125.701685   \n",
       "3   YAF_numb_angry.wav     0.294158  0.065479        3015.999826   \n",
       "4  YAF_seize_angry.wav     0.294656  0.034536        4283.769099   \n",
       "\n",
       "   spectral_bandwidth      rolloff  zero_crossing_rate       mfcc1      mfcc2  \\\n",
       "0         2216.685828  3984.838867            0.101251 -409.611389  49.869926   \n",
       "1         2256.036375  3958.520508            0.094523 -388.562958  62.383816   \n",
       "2         2094.000747  3457.238582            0.099099 -405.522919  63.094051   \n",
       "3         2162.348090  5117.997675            0.175675 -306.055756  40.761471   \n",
       "4         2234.925543  6427.347542            0.288214 -372.893768   4.074799   \n",
       "\n",
       "       mfcc3  ...     mfcc12     mfcc13    mfcc14    mfcc15    mfcc16  \\\n",
       "0  -4.398498  ...   2.592276  -1.143469  6.888781 -2.693643 -0.001758   \n",
       "1 -10.005765  ...   7.899292  -2.929130 -0.960948  5.303476  2.484355   \n",
       "2 -23.975689  ...  15.111687  -0.581255  4.787343  0.885953  3.654622   \n",
       "3 -11.389371  ...  12.775775  -8.295956  7.579611  2.391619 -3.962322   \n",
       "4  14.011549  ...   8.256427 -11.015532  5.854211 -2.778954 -2.978256   \n",
       "\n",
       "     mfcc17     mfcc18    mfcc19     mfcc20  label  \n",
       "0  3.174780  -2.620514 -2.477835 -10.139343  angry  \n",
       "1 -8.288725 -10.059808 -6.154644 -11.985009  angry  \n",
       "2 -7.576045  -7.957401 -2.184226 -12.305842  angry  \n",
       "3  0.059314   1.836014 -8.889676   1.407364  angry  \n",
       "4  4.731396  -0.114971 -6.256421   6.497686  angry  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfcddc5",
   "metadata": {},
   "source": [
    "## 2. Заполнение csv файла обработанными данными из датасета RAVDESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81cc923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "repl_dict = {\"1\": \"neutral\",\n",
    "             \"3\": \"happy\",\n",
    "             \"4\": \"sad\",\n",
    "             \"5\": \"angry\",\n",
    "             \"6\": \"fear\",\n",
    "             \"7\": \"disgust\",\n",
    "             \"8\": \"pleasant_surprised\"}\n",
    "\n",
    "for filename in os.listdir(f\"./RAVDESS\"):\n",
    "    if filename == \".DS_Store\" or filename[7] == \"2\":\n",
    "        continue\n",
    "    songname = f\"./RAVDESS/{filename}\"\n",
    "    y, sr = librosa.load(songname, mono=True)\n",
    "\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "\n",
    "    feature_row = f'{filename} {np.mean(chroma_stft)} {np.mean(rms)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "\n",
    "    for e in mfcc:\n",
    "        feature_row += f' {np.mean(e)}'\n",
    "    feature_row += f' {repl_dict[filename[7]]}'\n",
    "    file = open('dataset.csv', 'a', newline='')\n",
    "    with file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(feature_row.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdfe05cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4048, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f6a26fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "angry                 592\n",
       "sad                   592\n",
       "happy                 592\n",
       "fear                  592\n",
       "disgust               592\n",
       "pleasant_surprised    592\n",
       "neutral               496\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Смотрим, есть ли у нас разбалансировка классов (как видим - нет, все замечательно)\n",
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3679fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c988ae6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9db8d5ea",
   "metadata": {},
   "source": [
    "## Обработка датасета и разделение на тренировочную и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b394888",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"filename\", \"label\"])\n",
    "y = pd.get_dummies(df[\"label\"])\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "289a3aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features.values, dtype = torch.float32)\n",
    "        self.labels = torch.tensor(labels.values, dtype = torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        return self.features[ind], self.labels[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43f7185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(x_train, y_train)\n",
    "test_dataset = MyDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb6718c",
   "metadata": {},
   "source": [
    "## Архитектура нашей нейронной сети и ее обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43c860d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecognizeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RecognizeNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(26, 100)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(100, 200)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(200, 100)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.layer4 = nn.Linear(100, 50)\n",
    "        self.act4 = nn.ReLU()\n",
    "        self.layer5 = nn.Linear(50, 7)\n",
    "        #self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.act3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.layer5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94f7fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecognizeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75c66a49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▌                                     | 101/1600 [00:08<01:51, 13.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1600], Loss: 1.2955, Accuracy: 44.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████                                   | 201/1600 [00:21<03:21,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/1600], Loss: 0.7160, Accuracy: 72.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████▌                                | 302/1600 [00:32<02:03, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [300/1600], Loss: 0.5327, Accuracy: 79.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████                              | 401/1600 [00:43<02:27,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [400/1600], Loss: 0.4249, Accuracy: 84.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████▌                           | 502/1600 [01:01<02:00,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/1600], Loss: 0.4581, Accuracy: 83.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████                         | 601/1600 [01:12<01:59,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [600/1600], Loss: 0.1923, Accuracy: 92.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████▌                      | 700/1600 [01:28<04:18,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [700/1600], Loss: 0.1751, Accuracy: 93.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████                    | 802/1600 [01:41<01:11, 11.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [800/1600], Loss: 0.1062, Accuracy: 96.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████▌                 | 902/1600 [01:50<01:00, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [900/1600], Loss: 0.0659, Accuracy: 97.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|████████████████████████▍              | 1002/1600 [01:59<00:53, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1000/1600], Loss: 0.0144, Accuracy: 99.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████████████████████████▊            | 1102/1600 [02:09<00:44, 11.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1100/1600], Loss: 0.0013, Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████▎         | 1201/1600 [02:19<00:39, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1200/1600], Loss: 0.0006, Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|███████████████████████████████▋       | 1300/1600 [02:28<00:28, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1300/1600], Loss: 0.0004, Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████▏    | 1402/1600 [02:41<00:32,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1400/1600], Loss: 0.0003, Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████▌  | 1501/1600 [02:56<00:11,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1500/1600], Loss: 0.0001, Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1600/1600 [03:09<00:00,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1600/1600], Loss: 0.0001, Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "epochs = 1600\n",
    "lr = 0.003\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "epoch = 0\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for i, batch in enumerate(train_loader):\n",
    "\n",
    "        x, y = batch\n",
    "        preds = model(x)\n",
    "\n",
    "        loss = loss_fn(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        preds = F.softmax(preds, dim=1)\n",
    "\n",
    "        total = y.size(0)\n",
    "        _, predicted = torch.max(preds.data, 1)\n",
    "        _, true = torch.max(y.data, 1)\n",
    "        correct = (predicted == true).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                  .format(epoch + 1, epochs, loss.item(),\n",
    "                          (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd533b9",
   "metadata": {},
   "source": [
    "## Тестирование нашей нейронки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad5709e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the Test Data: 84.07407407407408 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in test_loader:\n",
    "        y_pred = model(x)\n",
    "        y_pred = F.softmax(y_pred, dim=1)\n",
    "        _, predicted = torch.max(y_pred.data, 1)\n",
    "        _, y_true = torch.max(y.data, 1)\n",
    "        total += y_true.size(0)\n",
    "        correct += (predicted == y_true).sum().item()\n",
    "\n",
    "    print('Accuracy of the model on the Test Data: {} %'.format((correct / total) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab24617",
   "metadata": {},
   "source": [
    "# Внедряем нашу нейронку (создание мини Голосового Ассистента)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6236c121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sounddevice in /opt/miniconda3/lib/python3.9/site-packages (0.4.6)\n",
      "Requirement already satisfied: CFFI>=1.0 in /opt/miniconda3/lib/python3.9/site-packages (from sounddevice) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /opt/miniconda3/lib/python3.9/site-packages (from CFFI>=1.0->sounddevice) (2.20)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: scipy in /opt/miniconda3/lib/python3.9/site-packages (1.9.3)\n",
      "Requirement already satisfied: numpy<1.26.0,>=1.18.5 in /opt/miniconda3/lib/python3.9/site-packages (from scipy) (1.20.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Устанавливаем библиотеки если они не установлены\n",
    "!pip3 install sounddevice\n",
    "!pip3 install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c02ac50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "  sounddevice\n",
    "from scipy.io.wavfile   write\n",
    "\n",
    "def voice_recorder(seconds, file):\n",
    "    print(\"Recording Started…\")\n",
    "    recording = sounddevice.rec((seconds * 44100), samplerate= 44100, channels=1)\n",
    "    sounddevice.wait()\n",
    "    write(file, 44100, recording)\n",
    "    print(\"Recording Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b367abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_dict = {\"0\": \"angry\",\n",
    "              \"1\": \"disgust\",\n",
    "              \"2\": \"fear\",\n",
    "              \"3\": \"happy\",\n",
    "              \"4\": \"neutral\",\n",
    "              \"5\": \"pleasant_surprised\",\n",
    "              \"6\": \"sad\"}\n",
    "\n",
    "def recognize_emotion(model=model, emo_dict=emo_dict, seconds=5):\n",
    "\n",
    "    songname = f\"{input()}.m4a\"\n",
    "    voice_recorder(seconds, songname)\n",
    "\n",
    "    y, sr = librosa.load(songname, mono=True)\n",
    "\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "\n",
    "    features = [np.mean(chroma_stft), np.mean(rms), np.mean(spec_cent), np.mean(spec_bw), np.mean(rolloff), np.mean(zcr)]\n",
    "\n",
    "    for e in mfcc:\n",
    "        features.append(np.mean(e))\n",
    "\n",
    "    features = torch.tensor(features, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        prediction = model(features)\n",
    "\n",
    "    pred_emo_index = torch.max(prediction.data, 0)[1].item()\n",
    "\n",
    "    print(f\"You are {emo_dict[str(pred_emo_index)].upper()}\")\n",
    "    return emo_dict[str(pred_emo_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dcdb791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "record\n",
      "Recording Started…\n",
      "Recording Finished\n",
      "You are PLEASANT_SURPRISED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'pleasant_surprised'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognize_emotion(seconds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f55d1165",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = [\"angry\", \"sad\", \"happy\", \"fear\", \"disgust\", \"neutral\", \"pleasant_surprised\"]\n",
    "\n",
    "answers = pd.read_csv(\"answers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efc4801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reply(seconds=5):\n",
    "    emotion = recognize_emotion(seconds=seconds)\n",
    "    answer = answers[emotion].sample().iloc[0]\n",
    "    t1 = gtts.gTTS(answer, tld=\"ru\", lang=\"ru\")\n",
    "    t1.save(\"answer.mp3\")\n",
    "    print(\"Отвечает...\")\n",
    "    playsound(\"answer.mp3\")\n",
    "    print(\"Ответ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "643cf537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "record\n",
      "Recording Started…\n",
      "Recording Finished\n",
      "You are ANGRY\n",
      "Отвечает...\n",
      "Ответ \n"
     ]
    }
   ],
   "source": [
    "reply(seconds=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
